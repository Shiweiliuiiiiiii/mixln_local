nohup: ignoring input
Training with learning rate: 1e-3, norm type: post on GPU 
Starting script
2024-10-23 14:50:41.498 | INFO     | __main__:main:141 - Global rank 0, local rank 0, device: 0
2024-10-23 14:50:41.504 | INFO     | __main__:main:145 - Process group initialized
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yinluu-cn. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in /home/lius/project/MixLN/wandb/run-20241023_145042-4n8nl17n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 350m_res_post_lr1e-3
wandb: ⭐️ View project at https://wandb.ai/yinluu-cn/galore-c4-7b
wandb: 🚀 View run at https://wandb.ai/yinluu-cn/galore-c4-7b/runs/4n8nl17n
2024-10-23 14:50:42.752 | INFO     | __main__:main:164 - Using dist with rank 0 (only rank 0 will log)
2024-10-23 14:50:42.753 | INFO     | __main__:main:165 - ****************************************
2024-10-23 14:50:42.754 | INFO     | __main__:main:166 - Starting training with the arguments
2024-10-23 14:50:42.755 | INFO     | __main__:main:168 - model_config                   configs/llama_350m.json
2024-10-23 14:50:42.756 | INFO     | __main__:main:168 - use_hf_model                   False
2024-10-23 14:50:42.758 | INFO     | __main__:main:168 - continue_from                  None
2024-10-23 14:50:42.760 | INFO     | __main__:main:168 - batch_size                     128
2024-10-23 14:50:42.761 | INFO     | __main__:main:168 - gradient_accumulation          4
2024-10-23 14:50:42.762 | INFO     | __main__:main:168 - total_batch_size               512
2024-10-23 14:50:42.764 | INFO     | __main__:main:168 - max_length                     256
2024-10-23 14:50:42.765 | INFO     | __main__:main:168 - optimizer                      adam
2024-10-23 14:50:42.766 | INFO     | __main__:main:168 - lr                             0.001
2024-10-23 14:50:42.795 | INFO     | __main__:main:168 - scheduler                      cosine
2024-10-23 14:50:42.798 | INFO     | __main__:main:168 - min_lr_ratio                   0.1
2024-10-23 14:50:42.800 | INFO     | __main__:main:168 - activation_checkpointing       False
2024-10-23 14:50:42.802 | INFO     | __main__:main:168 - weight_decay                   0.0
2024-10-23 14:50:42.804 | INFO     | __main__:main:168 - warmup_steps                   6000
2024-10-23 14:50:42.806 | INFO     | __main__:main:168 - eval_every                     1000
2024-10-23 14:50:42.808 | INFO     | __main__:main:168 - num_training_steps             60000
2024-10-23 14:50:42.810 | INFO     | __main__:main:168 - max_train_tokens               None
2024-10-23 14:50:42.811 | INFO     | __main__:main:168 - save_every                     1000000000
2024-10-23 14:50:42.813 | INFO     | __main__:main:168 - save_dir                       /scratch/shiwei/models/350m_res_post_lr1e-3
2024-10-23 14:50:42.814 | INFO     | __main__:main:168 - tags                           None
2024-10-23 14:50:42.816 | INFO     | __main__:main:168 - dtype                          bfloat16
2024-10-23 14:50:42.818 | INFO     | __main__:main:168 - workers                        8
2024-10-23 14:50:42.819 | INFO     | __main__:main:168 - seed                           0
2024-10-23 14:50:42.821 | INFO     | __main__:main:168 - name                           test
2024-10-23 14:50:42.823 | INFO     | __main__:main:168 - grad_clipping                  0.0
2024-10-23 14:50:42.824 | INFO     | __main__:main:168 - run_name                       350m_res_post_lr1e-3
2024-10-23 14:50:42.826 | INFO     | __main__:main:168 - beta1                          0.0
2024-10-23 14:50:42.827 | INFO     | __main__:main:168 - rank                           128
2024-10-23 14:50:42.828 | INFO     | __main__:main:168 - update_proj_gap                50
2024-10-23 14:50:42.829 | INFO     | __main__:main:168 - galore_scale                   1.0
2024-10-23 14:50:42.831 | INFO     | __main__:main:168 - proj_type                      std
2024-10-23 14:50:42.832 | INFO     | __main__:main:168 - single_gpu                     False
2024-10-23 14:50:42.834 | INFO     | __main__:main:169 - ****************************************
2024-10-23 14:50:55.612 | INFO     | __main__:main:176 - Shuffling data with seed 32
/home/lius/miniconda3/envs/galore/lib/python3.8/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
Hi, 🙍‍♂️️the norm type is: post
wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Update steps:   0%|                                   | 0/60000 [00:00<?, ?it/s]2024-10-23 14:51:00.929 | INFO     | __main__:main:291 - 
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 1024, padding_idx=31999)
    (layers): ModuleList(
      (0-23): 24 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=1024, out_features=2736, bias=False)
          (down_proj): Linear(in_features=2736, out_features=1024, bias=False)
          (up_proj): Linear(in_features=1024, out_features=2736, bias=False)
          (act_fn): SiLUActivation()
        )
        (post_feedforward_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)
)

2024-10-23 14:51:00.931 | INFO     | __main__:main:292 - Total params: 367.97M
2024-10-23 14:51:00.933 | INFO     | __main__:main:293 - Trainable params: 367.97M
2024-10-23 14:51:00.935 | INFO     | __main__:main:296 - Saving model to /scratch/shiwei/models/350m_res_post_lr1e-3 every 1000000000 update steps
Update steps:   0%|                       | 1/60000 [00:07<126:29:01,  7.59s/it]Update steps:   0%|                        | 2/60000 [00:09<67:27:13,  4.05s/it]Update steps:   0%|                        | 3/60000 [00:10<48:18:40,  2.90s/it]Update steps:   0%|                        | 4/60000 [00:12<39:22:01,  2.36s/it]Update steps:   0%|                        | 5/60000 [00:13<34:26:17,  2.07s/it]Update steps:   0%|                        | 6/60000 [00:15<31:27:57,  1.89s/it]Update steps:   0%|                        | 7/60000 [00:16<29:34:21,  1.77s/it]Update steps:   0%|                        | 8/60000 [00:18<28:22:32,  1.70s/it]Update steps:   0%|                        | 9/60000 [00:19<27:35:17,  1.66s/it]Update steps:   0%|                       | 10/60000 [00:21<27:05:23,  1.63s/it]Update steps:   0%|                       | 11/60000 [00:23<26:43:00,  1.60s/it]Update steps:   0%|                       | 12/60000 [00:24<26:25:45,  1.59s/it]Update steps:   0%|                       | 13/60000 [00:26<26:15:06,  1.58s/it]Update steps:   0%|                       | 14/60000 [00:27<26:08:30,  1.57s/it]Update steps:   0%|                       | 15/60000 [00:29<26:02:38,  1.56s/it]Update steps:   0%|                       | 16/60000 [00:30<26:00:47,  1.56s/it]Update steps:   0%|                       | 17/60000 [00:32<26:00:30,  1.56s/it]Update steps:   0%|                       | 18/60000 [00:33<26:00:34,  1.56s/it]Update steps:   0%|                       | 19/60000 [00:35<26:00:12,  1.56s/it]Update steps:   0%|                       | 20/60000 [00:37<25:58:45,  1.56s/it]Update steps:   0%|                       | 21/60000 [00:38<25:59:40,  1.56s/it]Update steps:   0%|                       | 22/60000 [00:40<25:59:51,  1.56s/it]Update steps:   0%|                       | 23/60000 [00:41<25:59:38,  1.56s/it]Update steps:   0%|                       | 24/60000 [00:43<25:59:38,  1.56s/it]Update steps:   0%|                       | 25/60000 [00:44<26:00:00,  1.56s/it]Update steps:   0%|                       | 26/60000 [00:46<25:59:45,  1.56s/it]Update steps:   0%|                       | 27/60000 [00:47<25:59:07,  1.56s/it]Update steps:   0%|                       | 28/60000 [00:49<25:59:34,  1.56s/it]Update steps:   0%|                       | 29/60000 [00:51<26:02:18,  1.56s/it]Update steps:   0%|                       | 30/60000 [00:52<26:01:43,  1.56s/it]Update steps:   0%|                       | 31/60000 [00:54<26:00:44,  1.56s/it]Update steps:   0%|                       | 32/60000 [00:55<26:02:49,  1.56s/it]Update steps:   0%|                       | 33/60000 [00:57<26:01:55,  1.56s/it]Update steps:   0%|                       | 34/60000 [00:58<26:01:18,  1.56s/it]Update steps:   0%|                       | 35/60000 [01:00<26:03:38,  1.56s/it]Update steps:   0%|                       | 36/60000 [01:02<26:04:35,  1.57s/it]Update steps:   0%|                       | 37/60000 [01:03<26:06:46,  1.57s/it]Update steps:   0%|                       | 38/60000 [01:05<26:06:56,  1.57s/it]Update steps:   0%|                       | 39/60000 [01:06<26:07:49,  1.57s/it]Update steps:   0%|                       | 40/60000 [01:08<26:07:46,  1.57s/it]Update steps:   0%|                       | 41/60000 [01:09<26:08:03,  1.57s/it]Update steps:   0%|                       | 42/60000 [01:11<26:07:04,  1.57s/it]Update steps:   0%|                       | 43/60000 [01:13<26:06:14,  1.57s/it]Update steps:   0%|                       | 44/60000 [01:14<26:06:43,  1.57s/it]Update steps:   0%|                       | 45/60000 [01:16<26:07:53,  1.57s/it]Update steps:   0%|                       | 46/60000 [01:17<26:07:29,  1.57s/it]Update steps:   0%|                       | 47/60000 [01:19<26:08:19,  1.57s/it]Update steps:   0%|                       | 48/60000 [01:20<26:08:54,  1.57s/it]Update steps:   0%|                       | 49/60000 [01:22<26:08:09,  1.57s/it]Update steps:   0%|                       | 50/60000 [01:24<26:08:32,  1.57s/it]Update steps:   0%|                       | 51/60000 [01:25<26:08:35,  1.57s/it]Update steps:   0%|                       | 52/60000 [01:27<26:08:39,  1.57s/it]Update steps:   0%|                       | 53/60000 [01:28<26:08:38,  1.57s/it]Update steps:   0%|                       | 54/60000 [01:30<26:09:21,  1.57s/it]Update steps:   0%|                       | 55/60000 [01:31<26:08:36,  1.57s/it]Update steps:   0%|                       | 56/60000 [01:33<26:08:17,  1.57s/it]Update steps:   0%|                       | 57/60000 [01:35<26:08:20,  1.57s/it]Update steps:   0%|                       | 58/60000 [01:36<26:09:05,  1.57s/it]Update steps:   0%|                       | 59/60000 [01:38<26:09:04,  1.57s/it]Update steps:   0%|                       | 60/60000 [01:39<26:08:27,  1.57s/it]Update steps:   0%|                       | 61/60000 [01:41<26:08:15,  1.57s/it]Update steps:   0%|                       | 62/60000 [01:42<26:09:51,  1.57s/it]Update steps:   0%|                       | 63/60000 [01:44<26:10:03,  1.57s/it]Update steps:   0%|                       | 64/60000 [01:46<26:10:06,  1.57s/it]Update steps:   0%|                       | 65/60000 [01:47<26:09:48,  1.57s/it]Update steps:   0%|                       | 66/60000 [01:49<26:09:32,  1.57s/it]Update steps:   0%|                       | 67/60000 [01:50<26:08:55,  1.57s/it]Update steps:   0%|                       | 68/60000 [01:52<26:09:38,  1.57s/it]Update steps:   0%|                       | 69/60000 [01:53<26:10:38,  1.57s/it]Update steps:   0%|                       | 70/60000 [01:55<26:11:15,  1.57s/it]Update steps:   0%|                       | 71/60000 [01:57<26:12:00,  1.57s/it]Update steps:   0%|                       | 72/60000 [01:58<26:12:55,  1.57s/it]Update steps:   0%|                       | 73/60000 [02:00<26:12:20,  1.57s/it]Update steps:   0%|                       | 74/60000 [02:01<26:12:58,  1.57s/it]Update steps:   0%|                       | 75/60000 [02:03<26:14:50,  1.58s/it]Update steps:   0%|                       | 76/60000 [02:04<26:14:30,  1.58s/it]Update steps:   0%|                       | 77/60000 [02:06<26:14:37,  1.58s/it]Update steps:   0%|                       | 78/60000 [02:08<26:13:52,  1.58s/it]Update steps:   0%|                       | 79/60000 [02:09<26:13:30,  1.58s/it]Update steps:   0%|                       | 80/60000 [02:11<26:15:01,  1.58s/it]Update steps:   0%|                       | 81/60000 [02:12<26:13:11,  1.58s/it]Update steps:   0%|                       | 82/60000 [02:14<26:12:58,  1.58s/it]Update steps:   0%|                       | 83/60000 [02:15<26:12:12,  1.57s/it]Update steps:   0%|                       | 84/60000 [02:17<26:13:02,  1.58s/it]Update steps:   0%|                       | 85/60000 [02:19<26:12:22,  1.57s/it]Update steps:   0%|                       | 86/60000 [02:20<26:11:46,  1.57s/it]Update steps:   0%|                       | 87/60000 [02:22<26:12:21,  1.57s/it]Update steps:   0%|                       | 88/60000 [02:23<26:13:35,  1.58s/it]Update steps:   0%|                       | 89/60000 [02:25<26:13:57,  1.58s/it]Update steps:   0%|                       | 90/60000 [02:26<26:13:44,  1.58s/it]Update steps:   0%|                       | 91/60000 [02:28<26:13:13,  1.58s/it]Update steps:   0%|                       | 92/60000 [02:30<26:11:07,  1.57s/it]Update steps:   0%|                       | 93/60000 [02:31<26:08:57,  1.57s/it]Update steps:   0%|                       | 94/60000 [02:33<26:06:02,  1.57s/it]Update steps:   0%|                       | 95/60000 [02:34<26:06:34,  1.57s/it]Update steps:   0%|                       | 96/60000 [02:36<26:06:19,  1.57s/it]Update steps:   0%|                       | 97/60000 [02:37<26:06:54,  1.57s/it]Update steps:   0%|                       | 98/60000 [02:39<26:07:05,  1.57s/it]Update steps:   0%|                       | 99/60000 [02:41<26:07:03,  1.57s/it]Update steps:   0%|                      | 100/60000 [02:42<26:07:01,  1.57s/it]Update steps:   0%|                      | 101/60000 [02:44<26:07:50,  1.57s/it]Update steps:   0%|                      | 102/60000 [02:45<26:07:23,  1.57s/it]Update steps:   0%|                      | 103/60000 [02:47<26:06:49,  1.57s/it]Update steps:   0%|                      | 104/60000 [02:48<26:06:57,  1.57s/it]Update steps:   0%|                      | 105/60000 [02:50<26:07:30,  1.57s/it]Update steps:   0%|                      | 106/60000 [02:52<26:06:56,  1.57s/it]Update steps:   0%|                      | 107/60000 [02:53<26:07:20,  1.57s/it]Update steps:   0%|                      | 108/60000 [02:55<26:07:23,  1.57s/it]Update steps:   0%|                      | 109/60000 [02:56<26:07:01,  1.57s/it]Update steps:   0%|                      | 110/60000 [02:58<26:07:00,  1.57s/it]Update steps:   0%|                      | 111/60000 [02:59<26:06:52,  1.57s/it]Update steps:   0%|                      | 112/60000 [03:01<26:06:59,  1.57s/it]Update steps:   0%|                      | 113/60000 [03:03<26:07:05,  1.57s/it]Update steps:   0%|                      | 114/60000 [03:04<26:07:18,  1.57s/it]Update steps:   0%|                      | 115/60000 [03:06<26:06:48,  1.57s/it]Update steps:   0%|                      | 116/60000 [03:07<26:06:55,  1.57s/it]Update steps:   0%|                      | 117/60000 [03:09<26:06:59,  1.57s/it]Update steps:   0%|                      | 118/60000 [03:10<26:06:56,  1.57s/it]Update steps:   0%|                      | 119/60000 [03:12<26:06:55,  1.57s/it]Update steps:   0%|                      | 120/60000 [03:14<26:06:56,  1.57s/it]Update steps:   0%|                      | 121/60000 [03:15<26:06:35,  1.57s/it]Update steps:   0%|                      | 122/60000 [03:17<26:06:42,  1.57s/it]Update steps:   0%|                      | 123/60000 [03:18<26:06:44,  1.57s/it]Update steps:   0%|                      | 124/60000 [03:20<26:06:36,  1.57s/it]Update steps:   0%|                      | 125/60000 [03:21<26:07:19,  1.57s/it]Update steps:   0%|                      | 126/60000 [03:23<26:06:25,  1.57s/it]Update steps:   0%|                      | 127/60000 [03:25<26:06:58,  1.57s/it]Update steps:   0%|                      | 128/60000 [03:26<26:06:38,  1.57s/it]Update steps:   0%|                      | 129/60000 [03:28<26:06:56,  1.57s/it]Update steps:   0%|                      | 130/60000 [03:29<26:06:32,  1.57s/it]Update steps:   0%|                      | 131/60000 [03:31<26:06:25,  1.57s/it]Update steps:   0%|                      | 132/60000 [03:32<26:06:46,  1.57s/it]Update steps:   0%|                      | 133/60000 [03:34<26:06:22,  1.57s/it]Update steps:   0%|                      | 134/60000 [03:36<26:06:55,  1.57s/it]Update steps:   0%|                      | 135/60000 [03:37<26:05:37,  1.57s/it]Update steps:   0%|                      | 136/60000 [03:39<26:06:52,  1.57s/it]Update steps:   0%|                      | 137/60000 [03:40<26:06:09,  1.57s/it]Update steps:   0%|                      | 138/60000 [03:42<26:07:39,  1.57s/it]Update steps:   0%|                      | 139/60000 [03:43<26:06:28,  1.57s/it]Update steps:   0%|                      | 140/60000 [03:45<26:06:04,  1.57s/it]Update steps:   0%|                      | 141/60000 [03:47<26:06:24,  1.57s/it]Update steps:   0%|                      | 142/60000 [03:48<26:06:07,  1.57s/it]Update steps:   0%|                      | 143/60000 [03:50<26:05:58,  1.57s/it]Update steps:   0%|                      | 144/60000 [03:51<26:06:18,  1.57s/it]Update steps:   0%|                      | 145/60000 [03:53<26:06:40,  1.57s/it]Update steps:   0%|                      | 146/60000 [03:54<26:06:15,  1.57s/it]Update steps:   0%|                      | 147/60000 [03:56<26:05:54,  1.57s/it]Update steps:   0%|                      | 148/60000 [03:58<26:05:53,  1.57s/it]Update steps:   0%|                      | 149/60000 [03:59<26:05:47,  1.57s/it]Update steps:   0%|                      | 150/60000 [04:01<26:06:09,  1.57s/it]Update steps:   0%|                      | 151/60000 [04:02<26:05:33,  1.57s/it]Update steps:   0%|                      | 152/60000 [04:04<26:06:04,  1.57s/it]Update steps:   0%|                      | 153/60000 [04:05<26:06:11,  1.57s/it]Update steps:   0%|                      | 154/60000 [04:07<26:06:14,  1.57s/it]Update steps:   0%|                      | 155/60000 [04:09<26:06:47,  1.57s/it]Update steps:   0%|                      | 156/60000 [04:10<26:05:51,  1.57s/it]Update steps:   0%|                      | 157/60000 [04:12<26:05:45,  1.57s/it]Update steps:   0%|                      | 158/60000 [04:13<26:05:52,  1.57s/it]Update steps:   0%|                      | 159/60000 [04:15<26:05:28,  1.57s/it]Update steps:   0%|                      | 160/60000 [04:16<26:05:51,  1.57s/it]Update steps:   0%|                      | 161/60000 [04:18<26:05:53,  1.57s/it]Update steps:   0%|                      | 162/60000 [04:20<26:05:34,  1.57s/it]Update steps:   0%|                      | 163/60000 [04:21<26:05:20,  1.57s/it]Update steps:   0%|                      | 164/60000 [04:23<26:05:51,  1.57s/it]Update steps:   0%|                      | 165/60000 [04:24<26:05:28,  1.57s/it]Update steps:   0%|                      | 166/60000 [04:26<26:05:35,  1.57s/it]Update steps:   0%|                      | 167/60000 [04:27<26:05:35,  1.57s/it]Update steps:   0%|                      | 168/60000 [04:29<26:05:34,  1.57s/it]Update steps:   0%|                      | 169/60000 [04:30<26:05:24,  1.57s/it]Update steps:   0%|                      | 170/60000 [04:32<26:06:19,  1.57s/it]Update steps:   0%|                      | 171/60000 [04:34<26:05:23,  1.57s/it]Update steps:   0%|                      | 172/60000 [04:35<26:05:53,  1.57s/it]Update steps:   0%|                      | 173/60000 [04:37<26:05:45,  1.57s/it]Update steps:   0%|                      | 174/60000 [04:38<26:05:49,  1.57s/it]Update steps:   0%|                      | 175/60000 [04:40<26:05:11,  1.57s/it]Update steps:   0%|                      | 176/60000 [04:41<26:04:51,  1.57s/it]Update steps:   0%|                      | 177/60000 [04:43<26:05:25,  1.57s/it]Update steps:   0%|                      | 178/60000 [04:45<26:04:56,  1.57s/it]Update steps:   0%|                      | 179/60000 [04:46<26:05:28,  1.57s/it]Update steps:   0%|                      | 180/60000 [04:48<26:04:47,  1.57s/it]Update steps:   0%|                      | 181/60000 [04:49<26:05:16,  1.57s/it]Update steps:   0%|                      | 182/60000 [04:51<26:05:10,  1.57s/it]Update steps:   0%|                      | 183/60000 [04:52<26:05:02,  1.57s/it]Update steps:   0%|                      | 184/60000 [04:54<26:04:58,  1.57s/it]Update steps:   0%|                      | 185/60000 [04:56<26:05:41,  1.57s/it]Update steps:   0%|                      | 186/60000 [04:57<26:07:03,  1.57s/it]Update steps:   0%|                      | 187/60000 [04:59<26:07:36,  1.57s/it]Update steps:   0%|                      | 188/60000 [05:00<26:07:28,  1.57s/it]